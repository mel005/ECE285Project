{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndefault setting is to run the model of Zhu, Park et al's\\nto set unet=True below to run the other two models\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchvision.utils as vutils\n",
    "import copy\n",
    "import math\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image, ImageFile\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data as td\n",
    "import torchvision as tv\n",
    "import pandas as pd\n",
    "from torch.autograd import Variable\n",
    "from io import BytesIO\n",
    "import itertools\n",
    "from image_pool import ImagePool\n",
    "import time\n",
    "from dataset import ArtDataset,LandscapeDataset,myimshow\n",
    "from model import weights_init,Generator,Discriminator,cal_loss_Cycle,cal_loss_Gan\n",
    "# from Unetmodel import weights_init,Generator,Discriminator,cal_loss_Cycle,cal_loss_Gan\n",
    "# from DnCNNmodel import weights_init,Generator,Discriminator,cal_loss_Cycle,cal_loss_Gan\n",
    "'''\n",
    "default setting is to run the model of Zhu, Park et al's\n",
    "to set unet=True below to run the other two models\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu' \n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize = 1\n",
    "landscape_root_dir = '/datasets/ee285f-public/flickr_landscape/'\n",
    "art_root_dir = '/datasets/ee285f-public/wikiart'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sets = LandscapeDataset(landscape_root_dir)\n",
    "X_loader =  list(td.DataLoader(X_sets, batch_size = batchsize, shuffle = True, pin_memory = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_sets = ArtDataset(art_root_dir)\n",
    "Y_loader =  list(td.DataLoader(Y_sets, batch_size = batchsize, shuffle = True, pin_memory = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (conv): ModuleList(\n",
       "    (0): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (2): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (bn): ModuleList(\n",
       "    (0): BatchNorm2d(3, eps=3, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): BatchNorm2d(3, eps=3, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): BatchNorm2d(3, eps=3, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (relu): ReLU(inplace)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_nc = 3    # the number of channels of input data\n",
    "output_nc = 3 # the number of channels of output data\n",
    "# Create the discriminator D_X--distinguish the image X in domain X and F(Y)\n",
    "D_X = Discriminator(input_nc).to(device)\n",
    "D_X.apply(weights_init)\n",
    "\n",
    "# Create the discriminator D_Y--distinguish the image Y in domain Y and G(X)\n",
    "D_Y = Discriminator(output_nc).to(device)\n",
    "D_X.apply(weights_init)\n",
    "\n",
    "\n",
    "unet=False  # if true, use Unet or DnCNN, if false, use encoder-resnet block-decoder\n",
    "if(unet):\n",
    "    # Create the generator G--Generator the image from X to Y domain\n",
    "    G = Generator(6).to(device)\n",
    "    # Create the generator F--Generator the image from Y to X domain\n",
    "    F=Generator(6).to(device)\n",
    "else:\n",
    "    G = Generator(input_nc, output_nc).to(device)    \n",
    "    F = Generator(input_nc, output_nc).to(device)\n",
    "G.apply(weights_init)\n",
    "F.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(num_epoch, D_X, D_Y, G, F, X_loader, Y_loader,  lamda = 10):\n",
    "    # Initialize the MSELoss function\n",
    "    criterion1 = nn.MSELoss()\n",
    "    # Initialize the L1Loss function\n",
    "    criterion2 = nn.L1Loss()\n",
    "    real_label = Variable(torch.cuda.FloatTensor(1).fill_(1.0), requires_grad = False)\n",
    "    fake_label = Variable(torch.cuda.FloatTensor(1).fill_(0.0), requires_grad = False)\n",
    "    # Setup Adam optimizers for D_X, D_Y, G, F\n",
    "    optimizerD_X = optim.Adam(D_X.parameters(), lr = 1e-3, betas=(0.5, 0.999))\n",
    "    optimizerD_Y = optim.Adam(D_Y.parameters(), lr = 1e-3, betas=(0.5, 0.999))\n",
    "    optimizerGenerator = optim.Adam(itertools.chain(G.parameters(), F.parameters()), lr = 1e-3, betas=(0.5, 0.999))\n",
    "    loss_Dx_plot=[]\n",
    "    loss_Dy_plot=[]\n",
    "    loss_cycle_plot=[]\n",
    "    for epoch in range(start_epoch, num_epoch):\n",
    "        fake_X_pool=ImagePool(50)\n",
    "        fake_Y_pool=ImagePool(50)\n",
    "        for i in range(len(X_loader)):\n",
    "            real_X = (X_loader[i]).cuda()\n",
    "            real_Y = (Y_loader[i]).cuda()\n",
    "            fake_X = F(real_Y)\n",
    "            fake_Y = G(real_X)\n",
    "            Y_D_1 = D_Y(fake_Y)\n",
    "            X_D_1 = D_X(fake_X)\n",
    "            \n",
    "            D_X.requires_grad = False\n",
    "            D_Y.requires_grad = False\n",
    "            optimizerGenerator.zero_grad()\n",
    "            gan_loss_X = criterion1(Y_D_1 , real_label)\n",
    "            gan_loss_Y = criterion1(X_D_1, real_label)\n",
    "            \n",
    "            loss_cycle = cal_loss_Cycle(F, real_X, fake_Y) + cal_loss_Cycle(G,real_Y,fake_X)\n",
    "            loss_G = lamda * loss_cycle + gan_loss_X + gan_loss_Y\n",
    "            loss_G.backward(retain_graph=True)\n",
    "            optimizerGenerator.step()\n",
    "            \n",
    "            # Update D_X network: minimize D_X(F(Y)**2 + (D_X(X) - 1)**2\n",
    "            D_X.requires_grad = True\n",
    "            D_X.zero_grad()\n",
    "            fake_X = fake_X_pool.query(fake_X)\n",
    "            loss_D_X = cal_loss_Gan(D_X, real_X, fake_X)   \n",
    "            loss_D_X.backward(retain_graph=True)\n",
    "            optimizerD_X.step()\n",
    "            \n",
    "            # Update D_Y network: minimize D_Y(G(X)**2 + (D_Y(Y) - 1)**2\n",
    "            D_Y.requires_grad = True\n",
    "            D_Y.zero_grad()\n",
    "            fake_Y= fake_Y_pool.query(fake_Y)\n",
    "            loss_D_Y = cal_loss_Gan(D_Y, real_Y, fake_Y)\n",
    "            loss_D_Y.backward(retain_graph = True) \n",
    "            optimizerD_Y.step()\n",
    "            \n",
    "            loss_total = loss_D_X + loss_D_Y + loss_cycle\n",
    "        \n",
    "        print(\"Epoch: {}/{}\".format(epoch, num_epoch))\n",
    "        print(\"Dx = {}, Dy = {}, cycle = {}, total loss = {}\".format(loss_D_X, loss_D_Y, loss_cycle, loss_total))\n",
    "        if(epoch%20 == 0):\n",
    "            plt.figure()\n",
    "            myimshow(G(X_loader[0].cuda())[0].detach())\n",
    "            loss_Dx_plot.append(loss_D_X)\n",
    "            loss_Dy_plot.append(loss_D_Y)\n",
    "            loss_cycle_plot.append(loss_cycle)\n",
    "         # Save models checkpoints\n",
    "        torch.save(G.state_dict(), 'output2/G.pth')\n",
    "        torch.save(F.state_dict(), 'output2/F.pth')\n",
    "        torch.save(D_X.state_dict(), 'output2/D_X.pth')\n",
    "        torch.save(D_Y.state_dict(), 'output2/D_Y.pth')\n",
    "    return loss_Dx_plot,loss_Dy_plot,loss_cycle_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_epoch=0\n",
    "num_epoch = 50\n",
    "if start_epoch != 0:\n",
    "    G.load_state_dict(torch.load('output/G.pth'))\n",
    "    F.load_state_dict(torch.load('output/F.pth'))\n",
    "    D_X.load_state_dict(torch.load('output/D_X.pth'))\n",
    "    D_Y.load_state_dict(torch.load('output/D_Y.pth'))\n",
    "else:\n",
    "    G.apply(weights_init)\n",
    "    F.apply(weights_init)\n",
    "    D_X.apply(weights_init)\n",
    "    D_Y.apply(weights_init)\n",
    "loss_Dx_plot,loss_Dy_plot,loss_cycle_plot=run(num_epoch, D_X, D_Y, G, F, X_loader, Y_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
